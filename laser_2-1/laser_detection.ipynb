{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "IMPORTING ULTRALYTICS LIBRARY\n"
      ],
      "metadata": {
        "id": "gQX4BGX0D-LL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T51vbtsb9D1r",
        "outputId": "56143383-0890-4114-cae6-affe5dbaaa39"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjqqMs85QZRS",
        "outputId": "8375707c-a3a8-4b14-fa5c-bccf29f4a24e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.120 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 24.1/78.2 GB disk)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "HOME=os.getcwd()\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "from IPython.display import display, Image"
      ],
      "metadata": {
        "id": "b67noeDnQg7p"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORTING DATASET FROM ROBOFLOW(WITH YAML FILE WHICH CONTAINS NO OF CLASSES AND TRAIN VAL LOCATIONS"
      ],
      "metadata": {
        "id": "uNQ9haS7ENe4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"dQgIFmcXM86FAuTYdF7v\")\n",
        "project = rf.workspace(\"matthew-cgj0a\").project(\"laser_2\")\n",
        "dataset = project.version(1).download(\"yolov8\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPZdmRRdQteF",
        "outputId": "5bc6ad1e-882b-4b9d-dfc2-eaf6958cb622"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Dependency ultralytics<=8.0.20 is required but found version=8.0.117, to fix: `pip install ultralytics<=8.0.20`\n",
            "Downloading Dataset Version Zip in laser_2-1 to yolov8: 100% [4565110 / 4565110] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to laser_2-1 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 766/766 [00:00<00:00, 3100.29it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/laser_2-1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSVyQmFjQ1BK",
        "outputId": "5158bbc4-0c6a-4add-81e3-eb85d3bfdccb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/laser_2-1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAINING CUSTOM YOLOV8 MODEL"
      ],
      "metadata": {
        "id": "NYYcBv5WEkoK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO('yolov8n.yaml')#nano\n",
        "model.train(data='data.yaml', epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZItbqFasRLrs",
        "outputId": "05ed4e4d-d0a3-477f-98a3-55a7c0c60d28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
            "YOLOv8n summary: 225 layers, 3157200 parameters, 3157184 gradients\n",
            "\n",
            "Ultralytics YOLOv8.0.117 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=data.yaml, epochs=50, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 12.1MB/s]\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "YOLOv8n summary: 225 layers, 3011043 parameters, 3011027 gradients\n",
            "\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to yolov8n.pt...\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.23M/6.23M [00:00<00:00, 33.3MB/s]\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/laser_2-1/train/labels... 263 images, 2 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 263/263 [00:00<00:00, 1800.45it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/laser_2-1/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/laser_2-1/valid/labels... 75 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:00<00:00, 2146.64it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/laser_2-1/valid/labels.cache\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/50      2.67G      3.679      114.3      3.273          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:08<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.31it/s]\n",
            "                   all         75         74          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/50       2.4G       5.08      48.79      3.835          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:03<00:00,  4.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.18it/s]\n",
            "                   all         75         74          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/50      2.41G      3.899      19.51      2.862         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  4.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.02it/s]\n",
            "                   all         75         74          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/50      2.41G      3.209      7.325      1.994         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  4.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.08it/s]\n",
            "                   all         75         74          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/50       2.4G      3.074      5.727      1.665          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:03<00:00,  4.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.22it/s]\n",
            "                   all         75         74          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/50      2.41G      2.997       4.94      1.561         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.53it/s]\n",
            "                   all         75         74     0.0008      0.243     0.0447     0.0162\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/50      2.41G      2.873      4.235      1.527         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:03<00:00,  4.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.22it/s]\n",
            "                   all         75         74      0.665      0.108      0.397      0.109\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/50      2.41G      2.791      3.641      1.471         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:03<00:00,  4.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.73it/s]\n",
            "                   all         75         74       0.39       0.23      0.232     0.0575\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/50       2.4G      2.893      3.832      1.573          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.74it/s]\n",
            "                   all         75         74      0.428        0.5      0.343     0.0908\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/50      2.41G      2.769      3.382      1.469         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:03<00:00,  4.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.02it/s]\n",
            "                   all         75         74      0.236      0.438      0.217     0.0661\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/50      2.41G      2.717      3.051      1.355          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.57it/s]\n",
            "                   all         75         74      0.292      0.568       0.33     0.0983\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/50      2.41G      2.725      3.067      1.402          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:03<00:00,  4.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.16it/s]\n",
            "                   all         75         74      0.359      0.622      0.401      0.119\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/50       2.4G      2.699      2.815      1.378         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:03<00:00,  4.63it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.14it/s]\n",
            "                   all         75         74      0.396      0.662       0.43      0.141\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/50      2.41G      2.646      2.529      1.362         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.91it/s]\n",
            "                   all         75         74      0.344      0.622      0.368      0.104\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/50      2.41G      2.681      2.395      1.379         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:03<00:00,  4.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.04it/s]\n",
            "                   all         75         74      0.514        0.5      0.566      0.181\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/50      2.41G      2.594      2.396      1.342         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.81it/s]\n",
            "                   all         75         74      0.346      0.554      0.287     0.0737\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/50       2.4G      2.613      2.229      1.313          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:03<00:00,  4.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.95it/s]\n",
            "                   all         75         74      0.496      0.473       0.44      0.132\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/50      2.41G       2.62      2.358      1.281         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:03<00:00,  4.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.44it/s]\n",
            "                   all         75         74      0.454      0.608      0.464      0.133\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/50      2.41G      2.529       2.12      1.263          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.45it/s]\n",
            "                   all         75         74      0.456      0.527      0.465      0.134\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/50      2.41G      2.569      2.213      1.336         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:03<00:00,  4.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.53it/s]\n",
            "                   all         75         74      0.444      0.649      0.476      0.157\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/50       2.4G      2.495        1.8      1.248         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:03<00:00,  4.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.27it/s]\n",
            "                   all         75         74      0.552      0.568      0.455      0.137\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/50      2.41G      2.552      1.844      1.263         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.01it/s]\n",
            "                   all         75         74      0.493      0.486      0.427      0.125\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/50      2.41G      2.482       1.98      1.276          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:03<00:00,  4.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.19it/s]\n",
            "                   all         75         74      0.675      0.534      0.603      0.179\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/50      2.41G      2.477      1.803      1.249         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.62it/s]\n",
            "                   all         75         74      0.555      0.574      0.544       0.15\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/50       2.4G      2.479      1.708      1.259          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:03<00:00,  4.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.87it/s]\n",
            "                   all         75         74      0.665      0.595      0.601      0.189\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      26/50      2.41G      2.468      1.742      1.237          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:03<00:00,  4.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.12it/s]\n",
            "                   all         75         74      0.283      0.568      0.254     0.0728\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      27/50      2.41G      2.497      1.719      1.257         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.26it/s]\n",
            "                   all         75         74      0.539      0.622      0.519      0.153\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      28/50      2.41G      2.603      1.748      1.289          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:03<00:00,  4.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.02it/s]\n",
            "                   all         75         74      0.489      0.662      0.484       0.15\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      29/50       2.4G      2.532      1.892      1.382          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  4.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.64it/s]\n",
            "                   all         75         74      0.395      0.676      0.424      0.139\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      30/50      2.41G      2.445      1.656      1.251         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  4.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.86it/s]\n",
            "                   all         75         74      0.614      0.568      0.535      0.162\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      31/50      2.41G      2.416      1.578       1.28          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:03<00:00,  4.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.74it/s]\n",
            "                   all         75         74      0.673       0.64      0.639      0.212\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      32/50      2.41G      2.487      1.732      1.314          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.72it/s]\n",
            "                   all         75         74      0.485      0.608      0.495      0.157\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      33/50       2.4G      2.399      1.671      1.238         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:03<00:00,  4.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.14it/s]\n",
            "                   all         75         74      0.452      0.649       0.48      0.144\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      34/50      2.41G      2.565       1.75      1.289          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:03<00:00,  4.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.16it/s]\n",
            "                   all         75         74      0.525      0.622      0.468      0.139\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      35/50      2.41G      2.417      1.599      1.266          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.11it/s]\n",
            "                   all         75         74      0.589      0.649      0.617      0.194\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      36/50      2.41G      2.423      1.584      1.252          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:03<00:00,  4.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.15it/s]\n",
            "                   all         75         74      0.542      0.575      0.481      0.151\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      37/50       2.4G      2.403      1.515      1.231          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.87it/s]\n",
            "                   all         75         74      0.362      0.514       0.32      0.095\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      38/50      2.41G      2.468      1.565      1.265          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:03<00:00,  4.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.46it/s]\n",
            "                   all         75         74      0.698      0.656      0.583      0.163\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      39/50      2.41G      2.459      1.447      1.242          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:03<00:00,  4.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.79it/s]\n",
            "                   all         75         74      0.642      0.581      0.593      0.181\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      40/50      2.41G      2.387      1.491      1.282          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.22it/s]\n",
            "                   all         75         74      0.609      0.676       0.57      0.172\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      41/50       2.4G      2.414      1.541      1.243          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:03<00:00,  4.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.57it/s]\n",
            "                   all         75         74      0.574      0.602      0.508      0.143\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      42/50      2.41G      2.377      1.489      1.243          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:03<00:00,  4.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.94it/s]\n",
            "                   all         75         74      0.547      0.568      0.494      0.162\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      43/50      2.41G      2.486       1.49      1.223          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.77it/s]\n",
            "                   all         75         74      0.478      0.554      0.427      0.137\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      44/50      2.41G      2.366      1.434      1.224         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:03<00:00,  4.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.13it/s]\n",
            "                   all         75         74      0.607      0.649      0.548      0.163\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      45/50       2.4G      2.292      1.361      1.192         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.78it/s]\n",
            "                   all         75         74      0.704      0.708      0.642      0.212\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      46/50      2.41G      2.448      1.419      1.271         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:03<00:00,  4.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.55it/s]\n",
            "                   all         75         74      0.655      0.689      0.567      0.179\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      47/50      2.41G      2.344       1.38      1.228         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:03<00:00,  4.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.18it/s]\n",
            "                   all         75         74      0.643      0.662      0.536      0.161\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      48/50      2.41G      2.358      1.374      1.211          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.15it/s]\n",
            "                   all         75         74      0.612      0.649      0.537      0.172\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      49/50       2.4G      2.352      1.373      1.237          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:03<00:00,  4.90it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.08it/s]\n",
            "                   all         75         74      0.606      0.623      0.567      0.178\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      50/50      2.41G      2.361      1.359      1.194         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  4.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.22s/it]\n",
            "                   all         75         74      0.599      0.622      0.551      0.179\n",
            "\n",
            "50 epochs completed in 0.083 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.117 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8n summary (fused): 168 layers, 3005843 parameters, 0 gradients\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.71it/s]\n",
            "                   all         75         74      0.704      0.708      0.641      0.213\n",
            "Speed: 4.3ms preprocess, 2.6ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TESTING THE TRAINED MODEL ON A SAMPLE VIDEO FOR VERIFICATION"
      ],
      "metadata": {
        "id": "qBuitgRaFBgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the YOLOv8 model\n",
        "model = YOLO('/content/laser_2-1/runs/detect/train/weights/best.pt')\n",
        "\n",
        "# Open the video file\n",
        "video_path = \"/content/drive/MyDrive/pexels-cottonbro-studio-8923305-4096x2160-25fps.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Loop through the video frames\n",
        "while cap.isOpened():\n",
        "    # Read a frame from the video\n",
        "    success, frame = cap.read()\n",
        "\n",
        "    if success:\n",
        "        # Run YOLOv8 inference on the frame\n",
        "        results = model(frame)\n",
        "\n",
        "        # Visualize the results on the frame\n",
        "        annotated_frame = results[0].plot()\n",
        "\n",
        "        # Display the annotated frame\n",
        "        #cv2_imshow(annotated_frame)\n",
        "\n",
        "        # Break the loop if 'q' is pressed\n",
        "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "            break\n",
        "    else:\n",
        "        # Break the loop if the end of the video is reached\n",
        "        break\n",
        "\n",
        "# Release the video capture object and close the display window\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7G7WTIfxRmVa",
        "outputId": "3750b813-fcf2-45e7-ea35-b624b762e4e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 352x640 1 target, 65.1ms\n",
            "Speed: 2.5ms preprocess, 65.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.0ms\n",
            "Speed: 3.1ms preprocess, 10.0ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 25.6ms\n",
            "Speed: 3.5ms preprocess, 25.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 17.6ms\n",
            "Speed: 4.2ms preprocess, 17.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.3ms\n",
            "Speed: 3.1ms preprocess, 9.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.4ms\n",
            "Speed: 2.7ms preprocess, 9.4ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 10.8ms\n",
            "Speed: 4.6ms preprocess, 10.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 3.1ms preprocess, 9.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.1ms\n",
            "Speed: 5.0ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.3ms\n",
            "Speed: 3.1ms preprocess, 9.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.2ms\n",
            "Speed: 3.1ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.4ms\n",
            "Speed: 3.1ms preprocess, 9.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.9ms\n",
            "Speed: 3.3ms preprocess, 8.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 3.1ms preprocess, 9.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 12.4ms\n",
            "Speed: 3.3ms preprocess, 12.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.5ms\n",
            "Speed: 3.0ms preprocess, 9.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.0ms\n",
            "Speed: 2.9ms preprocess, 10.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 2.9ms preprocess, 9.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.9ms\n",
            "Speed: 3.0ms preprocess, 10.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.1ms\n",
            "Speed: 3.1ms preprocess, 9.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.3ms\n",
            "Speed: 3.0ms preprocess, 9.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.4ms\n",
            "Speed: 3.3ms preprocess, 9.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 3.0ms preprocess, 9.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.1ms\n",
            "Speed: 3.4ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 4.0ms preprocess, 9.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.0ms\n",
            "Speed: 3.1ms preprocess, 9.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.1ms\n",
            "Speed: 3.2ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.2ms\n",
            "Speed: 3.3ms preprocess, 9.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 8.8ms\n",
            "Speed: 2.9ms preprocess, 8.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 3 targets, 9.4ms\n",
            "Speed: 3.7ms preprocess, 9.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 16.9ms\n",
            "Speed: 4.5ms preprocess, 16.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.5ms\n",
            "Speed: 2.9ms preprocess, 9.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.4ms\n",
            "Speed: 3.1ms preprocess, 9.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.0ms\n",
            "Speed: 3.1ms preprocess, 9.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.0ms\n",
            "Speed: 3.0ms preprocess, 9.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.1ms\n",
            "Speed: 5.1ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 8.8ms\n",
            "Speed: 3.1ms preprocess, 8.8ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 20.5ms\n",
            "Speed: 2.9ms preprocess, 20.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.4ms\n",
            "Speed: 4.0ms preprocess, 9.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.1ms\n",
            "Speed: 2.9ms preprocess, 10.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 2.9ms preprocess, 9.2ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.3ms\n",
            "Speed: 3.0ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.1ms\n",
            "Speed: 4.1ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.0ms\n",
            "Speed: 4.3ms preprocess, 9.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.3ms\n",
            "Speed: 2.8ms preprocess, 9.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 14.6ms\n",
            "Speed: 3.1ms preprocess, 14.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 18.7ms\n",
            "Speed: 4.9ms preprocess, 18.7ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.9ms\n",
            "Speed: 4.0ms preprocess, 8.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.0ms\n",
            "Speed: 3.2ms preprocess, 10.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 3.4ms preprocess, 9.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.0ms\n",
            "Speed: 3.0ms preprocess, 10.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.1ms\n",
            "Speed: 3.5ms preprocess, 9.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 4.3ms preprocess, 9.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.3ms\n",
            "Speed: 3.0ms preprocess, 10.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.4ms\n",
            "Speed: 3.7ms preprocess, 9.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 3.1ms preprocess, 9.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.7ms\n",
            "Speed: 4.8ms preprocess, 9.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.8ms\n",
            "Speed: 2.9ms preprocess, 8.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.4ms\n",
            "Speed: 2.8ms preprocess, 9.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.5ms\n",
            "Speed: 3.0ms preprocess, 9.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.4ms\n",
            "Speed: 3.1ms preprocess, 10.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.9ms\n",
            "Speed: 3.2ms preprocess, 9.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.8ms\n",
            "Speed: 3.3ms preprocess, 10.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.6ms\n",
            "Speed: 3.0ms preprocess, 9.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.3ms\n",
            "Speed: 4.7ms preprocess, 9.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.1ms\n",
            "Speed: 4.3ms preprocess, 9.1ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.1ms\n",
            "Speed: 3.0ms preprocess, 9.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.5ms\n",
            "Speed: 2.9ms preprocess, 9.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.0ms\n",
            "Speed: 2.9ms preprocess, 9.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 12.7ms\n",
            "Speed: 3.6ms preprocess, 12.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.9ms\n",
            "Speed: 2.8ms preprocess, 9.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.1ms\n",
            "Speed: 3.4ms preprocess, 9.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.8ms\n",
            "Speed: 2.8ms preprocess, 8.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.5ms\n",
            "Speed: 3.8ms preprocess, 8.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.5ms\n",
            "Speed: 2.9ms preprocess, 10.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.0ms\n",
            "Speed: 2.8ms preprocess, 9.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.1ms\n",
            "Speed: 2.8ms preprocess, 9.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.4ms\n",
            "Speed: 2.9ms preprocess, 9.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.9ms\n",
            "Speed: 3.8ms preprocess, 8.9ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.4ms\n",
            "Speed: 3.5ms preprocess, 9.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.8ms\n",
            "Speed: 3.5ms preprocess, 8.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.0ms\n",
            "Speed: 3.7ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.0ms\n",
            "Speed: 3.0ms preprocess, 9.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 4.1ms preprocess, 9.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.0ms\n",
            "Speed: 3.4ms preprocess, 9.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.1ms\n",
            "Speed: 3.2ms preprocess, 10.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.1ms\n",
            "Speed: 3.7ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.0ms\n",
            "Speed: 3.1ms preprocess, 9.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.1ms\n",
            "Speed: 3.7ms preprocess, 9.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 36.8ms\n",
            "Speed: 3.8ms preprocess, 36.8ms inference, 8.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 22.7ms\n",
            "Speed: 13.0ms preprocess, 22.7ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 30.2ms\n",
            "Speed: 7.2ms preprocess, 30.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 3.0ms preprocess, 9.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.8ms\n",
            "Speed: 3.3ms preprocess, 10.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.9ms\n",
            "Speed: 3.0ms preprocess, 8.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.7ms\n",
            "Speed: 3.4ms preprocess, 8.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 7.7ms\n",
            "Speed: 3.4ms preprocess, 7.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 11.5ms\n",
            "Speed: 3.7ms preprocess, 11.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.1ms\n",
            "Speed: 4.9ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 21.4ms\n",
            "Speed: 3.6ms preprocess, 21.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 16.8ms\n",
            "Speed: 7.5ms preprocess, 16.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 32.9ms\n",
            "Speed: 3.2ms preprocess, 32.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.1ms\n",
            "Speed: 4.0ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.6ms\n",
            "Speed: 3.6ms preprocess, 10.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 11.3ms\n",
            "Speed: 3.8ms preprocess, 11.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.1ms\n",
            "Speed: 3.5ms preprocess, 9.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.0ms\n",
            "Speed: 3.1ms preprocess, 9.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.4ms\n",
            "Speed: 3.3ms preprocess, 9.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.7ms\n",
            "Speed: 4.0ms preprocess, 9.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 13.2ms\n",
            "Speed: 3.0ms preprocess, 13.2ms inference, 27.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 67.7ms\n",
            "Speed: 5.1ms preprocess, 67.7ms inference, 15.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 22.7ms\n",
            "Speed: 16.4ms preprocess, 22.7ms inference, 9.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 24.1ms\n",
            "Speed: 3.9ms preprocess, 24.1ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 23.3ms\n",
            "Speed: 5.4ms preprocess, 23.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.8ms\n",
            "Speed: 5.2ms preprocess, 9.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.8ms\n",
            "Speed: 4.2ms preprocess, 8.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 23.3ms\n",
            "Speed: 2.9ms preprocess, 23.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.3ms\n",
            "Speed: 5.9ms preprocess, 9.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.0ms\n",
            "Speed: 3.5ms preprocess, 8.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 15.1ms\n",
            "Speed: 3.9ms preprocess, 15.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.4ms\n",
            "Speed: 2.9ms preprocess, 9.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.8ms\n",
            "Speed: 3.0ms preprocess, 10.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 15.2ms\n",
            "Speed: 10.0ms preprocess, 15.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 15.7ms\n",
            "Speed: 2.9ms preprocess, 15.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 23.3ms\n",
            "Speed: 2.9ms preprocess, 23.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 8.1ms\n",
            "Speed: 4.8ms preprocess, 8.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 17.8ms\n",
            "Speed: 3.1ms preprocess, 17.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 8.5ms\n",
            "Speed: 4.3ms preprocess, 8.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 12.2ms\n",
            "Speed: 7.7ms preprocess, 12.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 8.6ms\n",
            "Speed: 2.9ms preprocess, 8.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 7.9ms\n",
            "Speed: 3.3ms preprocess, 7.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 15.2ms\n",
            "Speed: 6.1ms preprocess, 15.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 14.4ms\n",
            "Speed: 3.6ms preprocess, 14.4ms inference, 10.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 23.6ms\n",
            "Speed: 6.0ms preprocess, 23.6ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 15.6ms\n",
            "Speed: 6.6ms preprocess, 15.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 15.6ms\n",
            "Speed: 7.6ms preprocess, 15.6ms inference, 9.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 16.3ms\n",
            "Speed: 2.8ms preprocess, 16.3ms inference, 9.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 8.8ms\n",
            "Speed: 4.0ms preprocess, 8.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.6ms\n",
            "Speed: 2.9ms preprocess, 9.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 8.5ms\n",
            "Speed: 4.9ms preprocess, 8.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 8.6ms\n",
            "Speed: 2.8ms preprocess, 8.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 10.3ms\n",
            "Speed: 3.1ms preprocess, 10.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 15.0ms\n",
            "Speed: 2.9ms preprocess, 15.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 24.0ms\n",
            "Speed: 2.9ms preprocess, 24.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 18.6ms\n",
            "Speed: 2.9ms preprocess, 18.6ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 20.2ms\n",
            "Speed: 3.1ms preprocess, 20.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 11.3ms\n",
            "Speed: 4.0ms preprocess, 11.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 24.7ms\n",
            "Speed: 2.9ms preprocess, 24.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.4ms\n",
            "Speed: 3.4ms preprocess, 10.4ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 16.5ms\n",
            "Speed: 5.5ms preprocess, 16.5ms inference, 10.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 2.7ms preprocess, 9.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.9ms\n",
            "Speed: 2.8ms preprocess, 8.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.7ms\n",
            "Speed: 2.9ms preprocess, 8.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.9ms\n",
            "Speed: 2.9ms preprocess, 8.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 7.8ms\n",
            "Speed: 3.6ms preprocess, 7.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.0ms\n",
            "Speed: 3.3ms preprocess, 9.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.0ms\n",
            "Speed: 3.3ms preprocess, 9.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.3ms\n",
            "Speed: 3.1ms preprocess, 9.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 8.4ms\n",
            "Speed: 3.6ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 8.8ms\n",
            "Speed: 2.9ms preprocess, 8.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 8.7ms\n",
            "Speed: 2.9ms preprocess, 8.7ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 8.8ms\n",
            "Speed: 3.5ms preprocess, 8.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.1ms\n",
            "Speed: 3.6ms preprocess, 9.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.9ms\n",
            "Speed: 3.1ms preprocess, 8.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.0ms\n",
            "Speed: 3.0ms preprocess, 9.0ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.3ms\n",
            "Speed: 3.0ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.5ms\n",
            "Speed: 3.0ms preprocess, 9.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.1ms\n",
            "Speed: 3.2ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.8ms\n",
            "Speed: 4.2ms preprocess, 8.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 8.9ms\n",
            "Speed: 3.1ms preprocess, 8.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.5ms\n",
            "Speed: 4.3ms preprocess, 9.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 4.2ms preprocess, 9.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.3ms\n",
            "Speed: 3.7ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.6ms\n",
            "Speed: 3.1ms preprocess, 8.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.1ms\n",
            "Speed: 4.1ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.5ms\n",
            "Speed: 3.2ms preprocess, 9.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.6ms\n",
            "Speed: 4.0ms preprocess, 8.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.8ms\n",
            "Speed: 9.4ms preprocess, 8.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 7.9ms\n",
            "Speed: 3.8ms preprocess, 7.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.7ms\n",
            "Speed: 3.3ms preprocess, 8.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.7ms\n",
            "Speed: 3.2ms preprocess, 8.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.1ms\n",
            "Speed: 3.2ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.9ms\n",
            "Speed: 2.4ms preprocess, 8.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.0ms\n",
            "Speed: 3.0ms preprocess, 9.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.8ms\n",
            "Speed: 2.9ms preprocess, 8.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.5ms\n",
            "Speed: 4.6ms preprocess, 9.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.3ms\n",
            "Speed: 2.7ms preprocess, 9.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 12.2ms\n",
            "Speed: 2.8ms preprocess, 12.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.3ms\n",
            "Speed: 2.8ms preprocess, 9.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 7.5ms\n",
            "Speed: 3.4ms preprocess, 7.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.7ms\n",
            "Speed: 3.2ms preprocess, 8.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.0ms\n",
            "Speed: 2.9ms preprocess, 9.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.6ms\n",
            "Speed: 3.4ms preprocess, 8.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.0ms\n",
            "Speed: 3.5ms preprocess, 8.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.3ms\n",
            "Speed: 4.1ms preprocess, 9.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.8ms\n",
            "Speed: 4.0ms preprocess, 8.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.6ms\n",
            "Speed: 3.9ms preprocess, 8.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 7.2ms\n",
            "Speed: 3.1ms preprocess, 7.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.6ms\n",
            "Speed: 3.2ms preprocess, 10.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.3ms\n",
            "Speed: 3.2ms preprocess, 9.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.7ms\n",
            "Speed: 4.0ms preprocess, 8.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.3ms\n",
            "Speed: 3.0ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.0ms\n",
            "Speed: 4.2ms preprocess, 9.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.3ms\n",
            "Speed: 3.6ms preprocess, 9.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.7ms\n",
            "Speed: 4.8ms preprocess, 8.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.5ms\n",
            "Speed: 3.0ms preprocess, 9.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 3.7ms preprocess, 9.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 2.8ms preprocess, 9.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.0ms\n",
            "Speed: 3.7ms preprocess, 9.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.6ms\n",
            "Speed: 3.0ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.0ms\n",
            "Speed: 3.3ms preprocess, 9.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.1ms\n",
            "Speed: 4.2ms preprocess, 9.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 11.3ms\n",
            "Speed: 4.5ms preprocess, 11.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.4ms\n",
            "Speed: 3.9ms preprocess, 9.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.6ms\n",
            "Speed: 3.6ms preprocess, 9.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.8ms\n",
            "Speed: 3.9ms preprocess, 8.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 21.0ms\n",
            "Speed: 2.9ms preprocess, 21.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.5ms\n",
            "Speed: 3.0ms preprocess, 9.5ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.1ms\n",
            "Speed: 3.3ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.0ms\n",
            "Speed: 3.1ms preprocess, 9.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.5ms\n",
            "Speed: 3.1ms preprocess, 9.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.9ms\n",
            "Speed: 2.8ms preprocess, 8.9ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 6.5ms\n",
            "Speed: 3.0ms preprocess, 6.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.2ms\n",
            "Speed: 3.6ms preprocess, 9.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.2ms\n",
            "Speed: 3.4ms preprocess, 9.2ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 8.2ms\n",
            "Speed: 3.5ms preprocess, 8.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 6.8ms\n",
            "Speed: 3.7ms preprocess, 6.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.5ms\n",
            "Speed: 3.1ms preprocess, 10.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.6ms\n",
            "Speed: 2.9ms preprocess, 9.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.4ms\n",
            "Speed: 3.2ms preprocess, 9.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.5ms\n",
            "Speed: 3.0ms preprocess, 9.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.8ms\n",
            "Speed: 2.7ms preprocess, 9.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 13.5ms\n",
            "Speed: 6.2ms preprocess, 13.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.6ms\n",
            "Speed: 4.1ms preprocess, 8.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.0ms\n",
            "Speed: 2.9ms preprocess, 10.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.0ms\n",
            "Speed: 2.9ms preprocess, 9.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 8.9ms\n",
            "Speed: 3.1ms preprocess, 8.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 8.9ms\n",
            "Speed: 2.9ms preprocess, 8.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 3.2ms preprocess, 9.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.9ms\n",
            "Speed: 3.7ms preprocess, 8.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 18.7ms\n",
            "Speed: 3.6ms preprocess, 18.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 3.6ms preprocess, 9.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.1ms\n",
            "Speed: 3.8ms preprocess, 9.1ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.9ms\n",
            "Speed: 2.7ms preprocess, 10.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.8ms\n",
            "Speed: 2.8ms preprocess, 9.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 7.8ms\n",
            "Speed: 3.0ms preprocess, 7.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.7ms\n",
            "Speed: 3.0ms preprocess, 9.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 13.7ms\n",
            "Speed: 3.1ms preprocess, 13.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 3.2ms preprocess, 9.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 7.3ms\n",
            "Speed: 3.7ms preprocess, 7.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 22.7ms\n",
            "Speed: 3.9ms preprocess, 22.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.9ms\n",
            "Speed: 2.9ms preprocess, 8.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.7ms\n",
            "Speed: 3.7ms preprocess, 8.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.6ms\n",
            "Speed: 3.7ms preprocess, 9.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.1ms\n",
            "Speed: 3.2ms preprocess, 9.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.8ms\n",
            "Speed: 3.7ms preprocess, 9.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 (no detections), 9.5ms\n",
            "Speed: 5.1ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 (no detections), 10.2ms\n",
            "Speed: 3.9ms preprocess, 10.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 (no detections), 10.0ms\n",
            "Speed: 3.2ms preprocess, 10.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 (no detections), 9.2ms\n",
            "Speed: 3.3ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 (no detections), 9.0ms\n",
            "Speed: 3.0ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 (no detections), 9.0ms\n",
            "Speed: 3.0ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 (no detections), 9.4ms\n",
            "Speed: 2.9ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 (no detections), 6.3ms\n",
            "Speed: 3.1ms preprocess, 6.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 (no detections), 8.9ms\n",
            "Speed: 3.4ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 (no detections), 16.9ms\n",
            "Speed: 3.0ms preprocess, 16.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 (no detections), 10.1ms\n",
            "Speed: 3.0ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 (no detections), 9.3ms\n",
            "Speed: 3.2ms preprocess, 9.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 (no detections), 8.9ms\n",
            "Speed: 3.1ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 (no detections), 9.8ms\n",
            "Speed: 3.1ms preprocess, 9.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 (no detections), 10.7ms\n",
            "Speed: 3.9ms preprocess, 10.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 (no detections), 8.8ms\n",
            "Speed: 3.0ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 (no detections), 9.0ms\n",
            "Speed: 3.8ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 (no detections), 9.8ms\n",
            "Speed: 3.7ms preprocess, 9.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.4ms\n",
            "Speed: 2.9ms preprocess, 9.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.7ms\n",
            "Speed: 3.1ms preprocess, 8.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 8.7ms\n",
            "Speed: 3.0ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 8.9ms\n",
            "Speed: 3.4ms preprocess, 8.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.5ms\n",
            "Speed: 5.6ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 10.1ms\n",
            "Speed: 3.6ms preprocess, 10.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 10.1ms\n",
            "Speed: 3.0ms preprocess, 10.1ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.1ms\n",
            "Speed: 3.3ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.4ms\n",
            "Speed: 3.2ms preprocess, 9.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.5ms\n",
            "Speed: 2.8ms preprocess, 9.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.8ms\n",
            "Speed: 2.9ms preprocess, 9.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 8.8ms\n",
            "Speed: 3.9ms preprocess, 8.8ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.9ms\n",
            "Speed: 3.5ms preprocess, 8.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 6.2ms\n",
            "Speed: 2.4ms preprocess, 6.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 7.2ms\n",
            "Speed: 3.0ms preprocess, 7.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 6.8ms\n",
            "Speed: 2.0ms preprocess, 6.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DETECTION ON A SAMPLE VIDEO AND SAVING THE VIDEO IN CORRESPODING OUTPUT PATH"
      ],
      "metadata": {
        "id": "LKVGRT1oFM1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the YOLOv8 model\n",
        "model = YOLO('/content/drive/MyDrive/laser_2-1/runs/detect/train/weights/best.pt')\n",
        "\n",
        "# Open the video file\n",
        "video_path = \"/content/drive/MyDrive/pexels-cottonbro-studio-8923305-4096x2160-25fps.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Get video properties\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "# Create a video writer object\n",
        "output_path = '/content/drive/MyDrive/annotated_video.mp4'\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "output_video = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "# Loop through the video frames\n",
        "while cap.isOpened():\n",
        "    # Read a frame from the video\n",
        "    success, frame = cap.read()\n",
        "\n",
        "    if success:\n",
        "        # Run YOLOv8 inference on the frame\n",
        "        results = model(frame)\n",
        "\n",
        "        # Visualize the results on the frame\n",
        "        annotated_frame = results[0].plot()\n",
        "\n",
        "        # Write the annotated frame to the output video\n",
        "        output_video.write(annotated_frame)\n",
        "\n",
        "        # Display the annotated frame\n",
        "        #cv2_imshow(annotated_frame)\n",
        "\n",
        "        # Break the loop if 'q' is pressed\n",
        "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "            break\n",
        "    else:\n",
        "        # Break the loop if the end of the video is reached\n",
        "        break\n",
        "\n",
        "# Release the video capture object, video writer, and close the display window\n",
        "cap.release()\n",
        "output_video.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puXejAnsT4tJ",
        "outputId": "ccddb91e-78c2-4c4a-e980-356244b9b113"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 352x640 1 target, 20.0ms\n",
            "Speed: 6.5ms preprocess, 20.0ms inference, 8.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 13.7ms\n",
            "Speed: 11.9ms preprocess, 13.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 23.6ms\n",
            "Speed: 6.5ms preprocess, 23.6ms inference, 9.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.5ms\n",
            "Speed: 4.9ms preprocess, 9.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 11.4ms\n",
            "Speed: 2.9ms preprocess, 11.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.4ms\n",
            "Speed: 3.4ms preprocess, 9.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 10.6ms\n",
            "Speed: 3.4ms preprocess, 10.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.4ms\n",
            "Speed: 4.6ms preprocess, 9.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.3ms\n",
            "Speed: 3.3ms preprocess, 9.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 11.1ms\n",
            "Speed: 3.2ms preprocess, 11.1ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 15.8ms\n",
            "Speed: 3.5ms preprocess, 15.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 3.0ms preprocess, 9.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.2ms\n",
            "Speed: 7.1ms preprocess, 10.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.4ms\n",
            "Speed: 3.2ms preprocess, 9.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 11.9ms\n",
            "Speed: 3.4ms preprocess, 11.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.4ms\n",
            "Speed: 3.1ms preprocess, 9.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 11.0ms\n",
            "Speed: 3.1ms preprocess, 11.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.4ms\n",
            "Speed: 4.6ms preprocess, 9.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 3.1ms preprocess, 9.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.3ms\n",
            "Speed: 4.4ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 10.5ms\n",
            "Speed: 3.0ms preprocess, 10.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.6ms\n",
            "Speed: 3.2ms preprocess, 9.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.7ms\n",
            "Speed: 3.6ms preprocess, 9.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.6ms\n",
            "Speed: 3.2ms preprocess, 9.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.4ms\n",
            "Speed: 4.3ms preprocess, 9.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.2ms\n",
            "Speed: 3.3ms preprocess, 9.2ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 11.0ms\n",
            "Speed: 3.2ms preprocess, 11.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.7ms\n",
            "Speed: 3.9ms preprocess, 9.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 10.2ms\n",
            "Speed: 3.4ms preprocess, 10.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 3 targets, 9.0ms\n",
            "Speed: 4.2ms preprocess, 9.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.0ms\n",
            "Speed: 3.3ms preprocess, 9.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.3ms\n",
            "Speed: 3.8ms preprocess, 9.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.5ms\n",
            "Speed: 3.2ms preprocess, 9.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.0ms\n",
            "Speed: 3.2ms preprocess, 9.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.9ms\n",
            "Speed: 3.2ms preprocess, 9.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.6ms\n",
            "Speed: 4.4ms preprocess, 9.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 10.3ms\n",
            "Speed: 5.4ms preprocess, 10.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.4ms\n",
            "Speed: 3.5ms preprocess, 9.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 11.7ms\n",
            "Speed: 4.9ms preprocess, 11.7ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.2ms\n",
            "Speed: 3.1ms preprocess, 8.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 3.0ms preprocess, 9.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.3ms\n",
            "Speed: 3.2ms preprocess, 10.3ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.2ms\n",
            "Speed: 3.6ms preprocess, 9.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.1ms\n",
            "Speed: 3.3ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.4ms\n",
            "Speed: 3.1ms preprocess, 9.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.5ms\n",
            "Speed: 3.2ms preprocess, 9.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.7ms\n",
            "Speed: 3.1ms preprocess, 9.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.8ms\n",
            "Speed: 3.1ms preprocess, 10.8ms inference, 16.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.5ms\n",
            "Speed: 3.1ms preprocess, 9.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 3.1ms preprocess, 9.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.1ms\n",
            "Speed: 5.6ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 3.2ms preprocess, 9.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.4ms\n",
            "Speed: 5.6ms preprocess, 8.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.1ms\n",
            "Speed: 3.2ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.3ms\n",
            "Speed: 2.9ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 2.9ms preprocess, 9.2ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 16.9ms\n",
            "Speed: 3.0ms preprocess, 16.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.1ms\n",
            "Speed: 3.3ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.9ms\n",
            "Speed: 3.1ms preprocess, 9.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 3.4ms preprocess, 9.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 12.1ms\n",
            "Speed: 5.2ms preprocess, 12.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 3.1ms preprocess, 9.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.9ms\n",
            "Speed: 3.1ms preprocess, 9.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.4ms\n",
            "Speed: 3.2ms preprocess, 9.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 3.2ms preprocess, 9.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.9ms\n",
            "Speed: 3.6ms preprocess, 9.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.1ms\n",
            "Speed: 3.1ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.0ms\n",
            "Speed: 3.2ms preprocess, 9.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.1ms\n",
            "Speed: 3.3ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.3ms\n",
            "Speed: 3.4ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 3.1ms preprocess, 9.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.5ms\n",
            "Speed: 3.1ms preprocess, 9.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.1ms\n",
            "Speed: 3.2ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.8ms\n",
            "Speed: 3.4ms preprocess, 10.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.1ms\n",
            "Speed: 3.4ms preprocess, 10.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.3ms\n",
            "Speed: 3.2ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 3.2ms preprocess, 9.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 14.0ms\n",
            "Speed: 6.8ms preprocess, 14.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.3ms\n",
            "Speed: 3.8ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.5ms\n",
            "Speed: 4.1ms preprocess, 9.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.0ms\n",
            "Speed: 3.1ms preprocess, 9.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.3ms\n",
            "Speed: 3.6ms preprocess, 10.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 11.5ms\n",
            "Speed: 3.1ms preprocess, 11.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.0ms\n",
            "Speed: 3.1ms preprocess, 9.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.8ms\n",
            "Speed: 3.5ms preprocess, 10.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 22.7ms\n",
            "Speed: 3.1ms preprocess, 22.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 21.1ms\n",
            "Speed: 3.1ms preprocess, 21.1ms inference, 9.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 17.1ms\n",
            "Speed: 5.2ms preprocess, 17.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 8.0ms\n",
            "Speed: 10.8ms preprocess, 8.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.0ms\n",
            "Speed: 3.1ms preprocess, 10.0ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 12.6ms\n",
            "Speed: 3.2ms preprocess, 12.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 14.0ms\n",
            "Speed: 4.2ms preprocess, 14.0ms inference, 8.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 15.6ms\n",
            "Speed: 2.9ms preprocess, 15.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 19.2ms\n",
            "Speed: 3.3ms preprocess, 19.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 27.7ms\n",
            "Speed: 3.4ms preprocess, 27.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 17.5ms\n",
            "Speed: 3.0ms preprocess, 17.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 24.7ms\n",
            "Speed: 3.0ms preprocess, 24.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 24.2ms\n",
            "Speed: 3.1ms preprocess, 24.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 13.5ms\n",
            "Speed: 3.0ms preprocess, 13.5ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 14.5ms\n",
            "Speed: 6.9ms preprocess, 14.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.4ms\n",
            "Speed: 2.9ms preprocess, 10.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 25.0ms\n",
            "Speed: 3.0ms preprocess, 25.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 14.0ms\n",
            "Speed: 3.4ms preprocess, 14.0ms inference, 9.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 16.9ms\n",
            "Speed: 3.0ms preprocess, 16.9ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 20.8ms\n",
            "Speed: 2.8ms preprocess, 20.8ms inference, 9.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.7ms\n",
            "Speed: 2.9ms preprocess, 10.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 15.4ms\n",
            "Speed: 10.5ms preprocess, 15.4ms inference, 10.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.1ms\n",
            "Speed: 3.4ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.5ms\n",
            "Speed: 3.5ms preprocess, 9.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.1ms\n",
            "Speed: 3.3ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.1ms\n",
            "Speed: 3.1ms preprocess, 10.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.1ms\n",
            "Speed: 3.0ms preprocess, 9.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.3ms\n",
            "Speed: 3.1ms preprocess, 9.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.8ms\n",
            "Speed: 3.3ms preprocess, 9.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.3ms\n",
            "Speed: 3.5ms preprocess, 9.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.1ms\n",
            "Speed: 3.2ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.5ms\n",
            "Speed: 3.1ms preprocess, 9.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 12.4ms\n",
            "Speed: 3.1ms preprocess, 12.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.1ms\n",
            "Speed: 3.5ms preprocess, 10.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.5ms\n",
            "Speed: 3.2ms preprocess, 9.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.1ms\n",
            "Speed: 3.1ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 11.0ms\n",
            "Speed: 3.1ms preprocess, 11.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 3.1ms preprocess, 9.2ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.3ms\n",
            "Speed: 3.3ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.0ms\n",
            "Speed: 3.0ms preprocess, 9.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.1ms\n",
            "Speed: 3.1ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.1ms\n",
            "Speed: 3.0ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 8.9ms\n",
            "Speed: 3.9ms preprocess, 8.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.0ms\n",
            "Speed: 2.9ms preprocess, 9.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 8.9ms\n",
            "Speed: 3.9ms preprocess, 8.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.8ms\n",
            "Speed: 3.0ms preprocess, 9.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.1ms\n",
            "Speed: 4.2ms preprocess, 9.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.2ms\n",
            "Speed: 3.0ms preprocess, 9.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.1ms\n",
            "Speed: 3.5ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 16.2ms\n",
            "Speed: 3.1ms preprocess, 16.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 12.7ms\n",
            "Speed: 3.1ms preprocess, 12.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 10.3ms\n",
            "Speed: 4.1ms preprocess, 10.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.6ms\n",
            "Speed: 3.3ms preprocess, 9.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.2ms\n",
            "Speed: 3.3ms preprocess, 9.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.1ms\n",
            "Speed: 3.2ms preprocess, 9.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.0ms\n",
            "Speed: 3.6ms preprocess, 9.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.2ms\n",
            "Speed: 3.4ms preprocess, 9.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.1ms\n",
            "Speed: 3.3ms preprocess, 9.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.9ms\n",
            "Speed: 3.1ms preprocess, 9.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.5ms\n",
            "Speed: 3.9ms preprocess, 9.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.4ms\n",
            "Speed: 3.1ms preprocess, 9.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.4ms\n",
            "Speed: 3.1ms preprocess, 9.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.3ms\n",
            "Speed: 3.2ms preprocess, 9.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 3.5ms preprocess, 9.2ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.0ms\n",
            "Speed: 3.0ms preprocess, 8.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.0ms\n",
            "Speed: 3.3ms preprocess, 9.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.8ms\n",
            "Speed: 5.3ms preprocess, 10.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.6ms\n",
            "Speed: 3.1ms preprocess, 9.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.2ms\n",
            "Speed: 3.1ms preprocess, 10.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 11.2ms\n",
            "Speed: 3.8ms preprocess, 11.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.3ms\n",
            "Speed: 3.6ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.4ms\n",
            "Speed: 3.1ms preprocess, 9.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.5ms\n",
            "Speed: 3.0ms preprocess, 9.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.8ms\n",
            "Speed: 3.6ms preprocess, 9.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.2ms\n",
            "Speed: 3.3ms preprocess, 9.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 12.2ms\n",
            "Speed: 4.3ms preprocess, 12.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 8.9ms\n",
            "Speed: 3.9ms preprocess, 8.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.6ms\n",
            "Speed: 5.1ms preprocess, 9.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.8ms\n",
            "Speed: 3.1ms preprocess, 9.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.5ms\n",
            "Speed: 4.7ms preprocess, 9.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.0ms\n",
            "Speed: 3.2ms preprocess, 9.0ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.8ms\n",
            "Speed: 2.8ms preprocess, 9.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.3ms\n",
            "Speed: 3.1ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 13.2ms\n",
            "Speed: 3.2ms preprocess, 13.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 8.8ms\n",
            "Speed: 3.1ms preprocess, 8.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.3ms\n",
            "Speed: 3.9ms preprocess, 9.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.1ms\n",
            "Speed: 4.4ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.7ms\n",
            "Speed: 3.2ms preprocess, 9.7ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.8ms\n",
            "Speed: 3.9ms preprocess, 8.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 3.8ms preprocess, 9.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.0ms\n",
            "Speed: 3.8ms preprocess, 9.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 11.0ms\n",
            "Speed: 3.9ms preprocess, 11.0ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.8ms\n",
            "Speed: 3.4ms preprocess, 8.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.1ms\n",
            "Speed: 4.0ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.6ms\n",
            "Speed: 3.0ms preprocess, 9.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.5ms\n",
            "Speed: 3.1ms preprocess, 9.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.3ms\n",
            "Speed: 2.8ms preprocess, 10.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 12.4ms\n",
            "Speed: 3.0ms preprocess, 12.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.2ms\n",
            "Speed: 2.8ms preprocess, 10.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.9ms\n",
            "Speed: 2.9ms preprocess, 9.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 3.1ms preprocess, 9.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.1ms\n",
            "Speed: 3.0ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.9ms\n",
            "Speed: 4.5ms preprocess, 9.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.9ms\n",
            "Speed: 3.1ms preprocess, 8.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 11.8ms\n",
            "Speed: 3.7ms preprocess, 11.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 15.7ms\n",
            "Speed: 3.1ms preprocess, 15.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 22.2ms\n",
            "Speed: 3.1ms preprocess, 22.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 19.2ms\n",
            "Speed: 3.1ms preprocess, 19.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 15.0ms\n",
            "Speed: 5.1ms preprocess, 15.0ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 17.8ms\n",
            "Speed: 3.0ms preprocess, 17.8ms inference, 8.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.4ms\n",
            "Speed: 5.5ms preprocess, 8.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.9ms\n",
            "Speed: 3.1ms preprocess, 10.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 16.8ms\n",
            "Speed: 3.1ms preprocess, 16.8ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 25.7ms\n",
            "Speed: 3.0ms preprocess, 25.7ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 17.4ms\n",
            "Speed: 5.7ms preprocess, 17.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 8.5ms\n",
            "Speed: 3.1ms preprocess, 8.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.2ms\n",
            "Speed: 3.0ms preprocess, 10.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 14.8ms\n",
            "Speed: 10.9ms preprocess, 14.8ms inference, 7.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 12.0ms\n",
            "Speed: 3.0ms preprocess, 12.0ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 20.6ms\n",
            "Speed: 3.1ms preprocess, 20.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 19.8ms\n",
            "Speed: 3.0ms preprocess, 19.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 15.1ms\n",
            "Speed: 4.9ms preprocess, 15.1ms inference, 6.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 15.3ms\n",
            "Speed: 2.9ms preprocess, 15.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 21.0ms\n",
            "Speed: 3.0ms preprocess, 21.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 15.1ms\n",
            "Speed: 3.1ms preprocess, 15.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 24.4ms\n",
            "Speed: 3.9ms preprocess, 24.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 20.9ms\n",
            "Speed: 4.9ms preprocess, 20.9ms inference, 6.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 17.7ms\n",
            "Speed: 6.4ms preprocess, 17.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.3ms\n",
            "Speed: 4.4ms preprocess, 10.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.5ms\n",
            "Speed: 3.0ms preprocess, 9.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.6ms\n",
            "Speed: 3.9ms preprocess, 10.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 3.7ms preprocess, 9.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.1ms\n",
            "Speed: 3.1ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.9ms\n",
            "Speed: 3.0ms preprocess, 10.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.0ms\n",
            "Speed: 3.2ms preprocess, 10.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.3ms\n",
            "Speed: 3.6ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.1ms\n",
            "Speed: 3.2ms preprocess, 10.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.3ms\n",
            "Speed: 3.1ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 10.7ms\n",
            "Speed: 3.2ms preprocess, 10.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.2ms\n",
            "Speed: 3.9ms preprocess, 9.2ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 8.0ms\n",
            "Speed: 4.1ms preprocess, 8.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.7ms\n",
            "Speed: 3.2ms preprocess, 10.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.1ms\n",
            "Speed: 3.5ms preprocess, 9.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 3.4ms preprocess, 9.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.1ms\n",
            "Speed: 3.5ms preprocess, 9.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.7ms\n",
            "Speed: 3.3ms preprocess, 9.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 3.1ms preprocess, 9.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 3.1ms preprocess, 9.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.0ms\n",
            "Speed: 3.2ms preprocess, 9.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 3.1ms preprocess, 9.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.6ms\n",
            "Speed: 3.2ms preprocess, 9.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.1ms\n",
            "Speed: 3.2ms preprocess, 9.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.2ms\n",
            "Speed: 3.0ms preprocess, 9.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 11.6ms\n",
            "Speed: 3.1ms preprocess, 11.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.4ms\n",
            "Speed: 3.3ms preprocess, 10.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.7ms\n",
            "Speed: 5.3ms preprocess, 9.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.1ms\n",
            "Speed: 3.1ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.3ms\n",
            "Speed: 4.8ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.7ms\n",
            "Speed: 3.7ms preprocess, 10.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.0ms\n",
            "Speed: 3.4ms preprocess, 9.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.6ms\n",
            "Speed: 3.4ms preprocess, 9.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.7ms\n",
            "Speed: 6.0ms preprocess, 9.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.0ms\n",
            "Speed: 3.2ms preprocess, 9.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 4.0ms preprocess, 9.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.4ms\n",
            "Speed: 3.6ms preprocess, 9.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.2ms\n",
            "Speed: 3.2ms preprocess, 9.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.7ms\n",
            "Speed: 3.2ms preprocess, 9.7ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.1ms\n",
            "Speed: 3.1ms preprocess, 9.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.4ms\n",
            "Speed: 8.2ms preprocess, 9.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.0ms\n",
            "Speed: 5.0ms preprocess, 10.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 10.1ms\n",
            "Speed: 6.0ms preprocess, 10.1ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 (no detections), 9.5ms\n",
            "Speed: 3.4ms preprocess, 9.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 (no detections), 11.7ms\n",
            "Speed: 3.0ms preprocess, 11.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 (no detections), 9.0ms\n",
            "Speed: 3.4ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 (no detections), 9.5ms\n",
            "Speed: 3.5ms preprocess, 9.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 (no detections), 9.0ms\n",
            "Speed: 3.3ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 (no detections), 9.2ms\n",
            "Speed: 3.1ms preprocess, 9.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 (no detections), 9.4ms\n",
            "Speed: 3.3ms preprocess, 9.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 (no detections), 9.0ms\n",
            "Speed: 3.5ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 (no detections), 9.3ms\n",
            "Speed: 3.1ms preprocess, 9.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 (no detections), 9.5ms\n",
            "Speed: 5.3ms preprocess, 9.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 (no detections), 9.9ms\n",
            "Speed: 3.5ms preprocess, 9.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 (no detections), 9.0ms\n",
            "Speed: 3.1ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 (no detections), 9.0ms\n",
            "Speed: 3.6ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 (no detections), 9.1ms\n",
            "Speed: 3.1ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 (no detections), 9.0ms\n",
            "Speed: 3.1ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 (no detections), 9.9ms\n",
            "Speed: 3.5ms preprocess, 9.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 (no detections), 10.1ms\n",
            "Speed: 3.6ms preprocess, 10.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 (no detections), 9.5ms\n",
            "Speed: 3.1ms preprocess, 9.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 14.3ms\n",
            "Speed: 3.2ms preprocess, 14.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.0ms\n",
            "Speed: 3.9ms preprocess, 9.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.7ms\n",
            "Speed: 3.1ms preprocess, 9.7ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 10.2ms\n",
            "Speed: 3.0ms preprocess, 10.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.1ms\n",
            "Speed: 4.0ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.8ms\n",
            "Speed: 3.1ms preprocess, 9.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.2ms\n",
            "Speed: 4.1ms preprocess, 9.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.2ms\n",
            "Speed: 3.2ms preprocess, 9.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.0ms\n",
            "Speed: 3.0ms preprocess, 9.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.3ms\n",
            "Speed: 4.5ms preprocess, 9.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.4ms\n",
            "Speed: 3.4ms preprocess, 9.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 2 targets, 9.6ms\n",
            "Speed: 4.7ms preprocess, 9.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 9.6ms\n",
            "Speed: 6.4ms preprocess, 9.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 7.1ms\n",
            "Speed: 3.5ms preprocess, 7.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 6.2ms\n",
            "Speed: 4.2ms preprocess, 6.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 352x640 1 target, 6.2ms\n",
            "Speed: 4.3ms preprocess, 6.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SPARSE optical flow\n",
        "'''import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import time\n",
        "\n",
        "\n",
        "lk_params = dict(winSize  = (15, 15),\n",
        "                maxLevel = 2,\n",
        "                criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
        "\n",
        "feature_params = dict(maxCorners = 20,\n",
        "                    qualityLevel = 0.3,\n",
        "                    minDistance = 10,\n",
        "                    blockSize = 7 )\n",
        "\n",
        "\n",
        "trajectory_len = 40\n",
        "detect_interval = 5\n",
        "trajectories = []\n",
        "frame_idx = 0\n",
        "\n",
        "\n",
        "cap = cv2.VideoCapture('/content/drive/MyDrive/Untitled.mp4')\n",
        "\n",
        "\n",
        "while True:\n",
        "\n",
        "    # start time to calculate FPS\n",
        "    start = time.time()\n",
        "\n",
        "    suc,frame = cap.read()\n",
        "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    img = frame.copy()\n",
        "\n",
        "    # Calculate optical flow for a sparse feature set using the iterative Lucas-Kanade Method\n",
        "    if len(trajectories) > 0:\n",
        "        img0, img1 = prev_gray, frame_gray\n",
        "        p0 = np.float32([trajectory[-1] for trajectory in trajectories]).reshape(-1, 1, 2)\n",
        "        p1, _st, _err = cv2.calcOpticalFlowPyrLK(img0, img1, p0, None, **lk_params)\n",
        "        p0r, _st, _err = cv2.calcOpticalFlowPyrLK(img1, img0, p1, None, **lk_params)\n",
        "        d = abs(p0-p0r).reshape(-1, 2).max(-1)\n",
        "        good = d < 1\n",
        "\n",
        "        new_trajectories = []\n",
        "\n",
        "        # Get all the trajectories\n",
        "        for trajectory, (x, y), good_flag in zip(trajectories, p1.reshape(-1, 2), good):\n",
        "            if not good_flag:\n",
        "                continue\n",
        "            trajectory.append((x, y))\n",
        "            if len(trajectory) > trajectory_len:\n",
        "                del trajectory[0]\n",
        "            new_trajectories.append(trajectory)\n",
        "            # Newest detected point\n",
        "            cv2.circle(img, (int(x), int(y)), 2, (0, 0, 255), -1)\n",
        "\n",
        "        trajectories = new_trajectories\n",
        "\n",
        "        # Draw all the trajectories\n",
        "        cv2.polylines(img, [np.int32(trajectory) for trajectory in trajectories], False, (0, 255, 0))\n",
        "        cv2.putText(img, 'track count: %d' % len(trajectories), (20, 50), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,0), 2)\n",
        "\n",
        "\n",
        "    # Update interval - When to update and detect new features\n",
        "    if frame_idx % detect_interval == 0:\n",
        "        mask = np.zeros_like(frame_gray)\n",
        "        mask[:] = 255\n",
        "\n",
        "        # Lastest point in latest trajectory\n",
        "        for x, y in [np.int32(trajectory[-1]) for trajectory in trajectories]:\n",
        "            cv2.circle(mask, (x, y), 5, 0, -1)\n",
        "\n",
        "        # Detect the good features to track\n",
        "        p = cv2.goodFeaturesToTrack(frame_gray, mask = mask, **feature_params)\n",
        "        if p is not None:\n",
        "            # If good features can be tracked - add that to the trajectories\n",
        "            for x, y in np.float32(p).reshape(-1, 2):\n",
        "                trajectories.append([(x, y)])\n",
        "\n",
        "\n",
        "    frame_idx += 1\n",
        "    prev_gray = frame_gray\n",
        "\n",
        "    # End time\n",
        "    end = time.time()\n",
        "    # calculate the FPS for current frame detection\n",
        "    fps = 1 / (end-start)\n",
        "\n",
        "    # Show Results\n",
        "    cv2.putText(img, f\"{fps:.2f} FPS\", (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "    #cv2_imshow(img)\n",
        "    #cv2_imshow(mask)\n",
        "\n",
        "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()'''"
      ],
      "metadata": {
        "id": "W46jIS6z4v1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import time\n",
        "\n",
        "lk_params = dict(winSize=(15, 15),\n",
        "                 maxLevel=2,\n",
        "                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
        "\n",
        "feature_params = dict(maxCorners = 1,\n",
        "                      qualityLevel=0.3,\n",
        "                      minDistance=1,\n",
        "                      blockSize=7)\n",
        "\n",
        "trajectory_len = 20\n",
        "detect_interval = 1\n",
        "trajectories = []\n",
        "frame_idx = 0\n",
        "\n",
        "cap = cv2.VideoCapture('/content/drive/MyDrive/Untitled.mp4')\n",
        "\n",
        "# Get video properties\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# Define the codec for the output video\n",
        "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "output = cv2.VideoWriter('output7.mp4', fourcc, fps, (width, height))\n",
        "\n",
        "while True:\n",
        "    # Start time to calculate FPS\n",
        "    start = time.time()\n",
        "\n",
        "    suc, frame = cap.read()\n",
        "    if not suc:\n",
        "        break\n",
        "\n",
        "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    img = frame.copy()\n",
        "\n",
        "    # Calculate optical flow for a sparse feature set using the iterative Lucas-Kanade Method\n",
        "    if len(trajectories) > 0:\n",
        "        img0, img1 = prev_gray, frame_gray\n",
        "        p0 = np.float32([trajectory[-1] for trajectory in trajectories]).reshape(-1, 1, 2)\n",
        "        p1, _st, _err = cv2.calcOpticalFlowPyrLK(img0, img1, p0, None, **lk_params)\n",
        "        p0r, _st, _err = cv2.calcOpticalFlowPyrLK(img1, img0, p1, None, **lk_params)\n",
        "        d = abs(p0 - p0r).reshape(-1, 2).max(-1)\n",
        "        good = d < 1\n",
        "\n",
        "        new_trajectories = []\n",
        "\n",
        "        # Get all the trajectories\n",
        "        for trajectory, (x, y), good_flag in zip(trajectories, p1.reshape(-1, 2), good):\n",
        "            if not good_flag:\n",
        "                continue\n",
        "            trajectory.append((x, y))\n",
        "            if len(trajectory) > trajectory_len:\n",
        "                del trajectory[0]\n",
        "            new_trajectories.append(trajectory)\n",
        "            # Newest detected point\n",
        "            cv2.circle(img, (int(x), int(y)), 2, (0, 0, 255), -1)\n",
        "\n",
        "        trajectories = new_trajectories\n",
        "\n",
        "        # Draw all the trajectories\n",
        "        cv2.polylines(img, [np.int32(trajectory) for trajectory in trajectories], False, (0, 255, 0))\n",
        "        cv2.putText(img, 'track count: %d' % len(trajectories), (20, 50), cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 0), 2)\n",
        "\n",
        "    # Update interval - When to update and detect new features\n",
        "    if frame_idx % detect_interval == 0:\n",
        "        mask = np.zeros_like(frame_gray)\n",
        "        mask[:] = 255\n",
        "\n",
        "        # Lastest point in latest trajectory\n",
        "        for x, y in [np.int32(trajectory[-1]) for trajectory in trajectories]:\n",
        "            cv2.circle(mask, (x, y), 5, 0, -1)\n",
        "\n",
        "        # Detect the good features to track\n",
        "        p = cv2.goodFeaturesToTrack(frame_gray, mask=mask, **feature_params)\n",
        "        if p is not None:\n",
        "            # If good features can be tracked - add that to the trajectories\n",
        "            for x, y in np.float32(p).reshape(-1, 2):\n",
        "                trajectories.append([(x, y)])\n",
        "\n",
        "    frame_idx += 1\n",
        "    prev_gray = frame_gray\n",
        "\n",
        "    # End time\n",
        "    end = time.time()\n",
        "    # Calculate the FPS for the current frame detection\n",
        "    fps = 1 / (end - start)\n",
        "\n",
        "    # Show results\n",
        "    cv2.putText(img, f\"{fps:.2f} FPS\", (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "    output.write(img)  # Write the frame with trajectories to the output video\n",
        "\n",
        "    #cv2.imshow('Output', img)\n",
        "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "output.release()\n",
        "cv2.destroyAllWindows()'''\n"
      ],
      "metadata": {
        "id": "HhgUw1_hB-06"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#using houghcircles\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import time\n",
        "\n",
        "lk_params = dict(winSize=(15, 15),\n",
        "                 maxLevel=2,\n",
        "                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
        "\n",
        "circle_params = dict(dp=1,\n",
        "                     minDist=20,\n",
        "                     param1=50,\n",
        "                     param2=30,\n",
        "                     minRadius=20,\n",
        "                     maxRadius=30)\n",
        "\n",
        "trajectory_len = 20\n",
        "detect_interval = 1\n",
        "trajectories = []\n",
        "frame_idx = 0\n",
        "\n",
        "cap = cv2.VideoCapture('/content/drive/MyDrive/Untitled.mp4')\n",
        "\n",
        "# Get video properties\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# Define the codec for the output video\n",
        "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "output = cv2.VideoWriter('output9.mp4', fourcc, fps, (width, height))\n",
        "\n",
        "while True:\n",
        "    # Start time to calculate FPS\n",
        "    start = time.time()\n",
        "\n",
        "    suc, frame = cap.read()\n",
        "    if not suc:\n",
        "        break\n",
        "\n",
        "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    img = frame.copy()\n",
        "\n",
        "    # Calculate optical flow for a sparse feature set using the iterative Lucas-Kanade Method\n",
        "    if len(trajectories) > 0:\n",
        "        img0, img1 = prev_gray, frame_gray\n",
        "        p0 = np.float32([trajectory[-1] for trajectory in trajectories]).reshape(-1, 1, 2)\n",
        "        p1, _st, _err = cv2.calcOpticalFlowPyrLK(img0, img1, p0, None, **lk_params)\n",
        "        p0r, _st, _err = cv2.calcOpticalFlowPyrLK(img1, img0, p1, None, **lk_params)\n",
        "        d = abs(p0 - p0r).reshape(-1, 2).max(-1)\n",
        "        good = d < 1\n",
        "\n",
        "        new_trajectories = []\n",
        "\n",
        "        # Get all the trajectories\n",
        "        for trajectory, (x, y), good_flag in zip(trajectories, p1.reshape(-1, 2), good):\n",
        "            if not good_flag:\n",
        "                continue\n",
        "            trajectory.append((x, y))\n",
        "            if len(trajectory) > trajectory_len:\n",
        "                del trajectory[0]\n",
        "            new_trajectories.append(trajectory)\n",
        "            # Newest detected point\n",
        "            cv2.circle(img, (int(x), int(y)), 2, (0, 0, 255), -1)\n",
        "\n",
        "        trajectories = new_trajectories\n",
        "\n",
        "        # Draw all the trajectories\n",
        "        cv2.polylines(img, [np.int32(trajectory) for trajectory in trajectories], False, (0, 255, 0))\n",
        "        cv2.putText(img, 'track count: %d' % len(trajectories), (20, 50), cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 0), 2)\n",
        "\n",
        "    # Update interval - When to update and detect new features\n",
        "    if frame_idx % detect_interval == 0:\n",
        "        mask = np.zeros_like(frame_gray)\n",
        "        mask[:] = 255\n",
        "\n",
        "        # Detect circular objects\n",
        "        circles = cv2.HoughCircles(frame_gray, cv2.HOUGH_GRADIENT, **circle_params)\n",
        "        if circles is not None:\n",
        "            circles = np.round(circles[0, :]).astype(int)\n",
        "            for (x, y, r) in circles:\n",
        "                trajectories.append([(x, y)])\n",
        "\n",
        "    frame_idx += 1\n",
        "    prev_gray = frame_gray\n",
        "\n",
        "    # End time\n",
        "    end = time.time()\n",
        "    # Calculate the FPS for the current frame detection\n",
        "    fps = 1 / (end - start)\n",
        "\n",
        "    # Show results\n",
        "    cv2.putText(img, f\"{fps:.2f} FPS\", (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "    output.write(img)  # Write the frame with trajectories to the output video\n",
        "\n",
        "    #cv2.imshow('Output', img)\n",
        "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "output.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "Ht8Q4u6RMeD_"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U06gyKfMa0fk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}